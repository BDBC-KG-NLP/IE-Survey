
# 关系抽取调研——学术界（更新中。。。

## 目录

  * [1. 任务](#1-任务)

    * [1.1. 任务定义](#11-任务定义)
    * [1.2. 数据集](#12-数据集)
    * [1.3. 评测标准](#13-评测标准)
    * [1.4. SOTA](#14-SOTA)

  * [2. 方法总结](#2-方法总结)

    * [2.1. 基于模式挖掘的方法](#21-基于模式挖掘的方法)

      * [2.1.1. 基于模板匹配的方法](#211-基于模板匹配的方法)
      * [2.1.2. 基于依存句法的方法](#212-基于依存句法)

    * [2.2. 监督学习](#22-监督学习)

      * [2.2.1. 机器学习](#221-机器学习)
        - [2.2.1.1. 基于特征向量的方法](#2211-基于特征向量的方法)
        - [2.2.1.2. 基于核函数的方法](#2212-基于核函数的方法)
      * [2.2.2. 深度学习](#222-深度学习)
        * 2.2.2.1. Pipeline（管道式）
        * 2.2.2.2. Joint（联合抽取式）
        * 2.2.2.3. 远监督学习

    * [2.3. 半监督/无监督方法](#23-半监督/无监督方法)
      * 2.3.1. Bootstrapping
      * 2.3.2. 联合训练
      * 2.3.3. 标签传播
      * 2.3.4. 关系实例聚类和关系类型词选择
      

* [4. Paper List](#4-paper-list)

  * [4.1. 论文列表](#11-论文列表)

    * [4.1.1. 监督类方法](#411-监督类方法)
    * [4.1.2. 远监督方法](#412-远监督方法)
  * 4.2. 论文解读

* [5.相关文献](#5-相关文献)

* [6.参考资源](#6-参考资源)

     

## 1. 任务

### 1.1. 任务定义

自动识别句子中实体之间具有的某种语义关系。根据参与实体的多少可以分为二元关系抽取（两个实体）和多元关系抽取（三个及以上实体）。

通过关注两个实体间的语义关系，可以得到（subject, relation, object）三元组，其中subject和object表示两个实体，relation表示实体间的语义关系。

根据处理数据源的不同，关系抽取可以分为以下三种：

- 面向结构化文本的关系抽取：包括表格文档、XML文档、数据库数据等
- 面向非结构化文本的关系抽取：纯文本
- 面向半结构化文本的关系抽取：介于结构化和非结构化之间

根据抽取文本的范围不同，关系抽取可以分为以下两种：

- 句子级关系抽取：从一个句子中判别两个实体间是何种语义关系
- 语料（篇章）级关系抽取：不限定两个目标实体所出现的上下文

根据所抽取领域的划分，关系抽取又可以分为以下两种：

- 限定域关系抽取：在一个或者多个限定的领域内对实体间的语义关系进行抽取，限定关系的类别，可看成是一个文本分类任务
- 开放域关系抽取：不限定关系的类别

限定域关系抽取方法：

- 基于模板的关系抽取方法：通过人工编辑或者学习得到的模板对文本中的实体关系进行抽取和判别，受限于模板的质量和覆盖度，可扩张性不强
- 基于机器学习的关系抽取方法：将关系抽取看成是一个分类问题





### 1.2. 数据集

- **ACE 2005**

  **数据集简介**：ACE2005语料库是语言数据联盟(LDC)发布的由实体，关系和事件注释组成的各种类型的数据，包括英语，阿拉伯语和中文培训数据，目标是开发自动内容提取技术，支持以文本形式自动处理人类语言。ACE语料解决了五个子任务的识别：entities、values、temporal expressions、relations and events。这些任务要求系统处理文档中的语言数据，然后为每个文档输出有关其中提到或讨论的实体，值，时间表达式，关系和事件的信息。

  **获取方式**：数据集收费，需在LDC联盟的官网上注册再购买，[LDC账号注册地址](https://catalog.ldc.upenn.edu/signup)       [ACE 2005 下载地址](https://catalog.ldc.upenn.edu/LDC2006T06)

- **TACRED**

  **数据集简介**：TACRED(TAC Relation Extraction Dataset)是一个拥有106264条实例的大规模关系抽取数据集，这些数据来自于每年的[TAC KBP（TAC Knowledge Base Population）](https://catalog.ldc.upenn.edu/LDC2018T03)比赛使用的语料库中的新闻专线和网络文本。包含了41关系类型，此外若句子无定义关系，被标注成no_relation类型。数据集的详细介绍可以访问[TACRED文档](https://nlp.stanford.edu/projects/tacred/)

  **获取方式**：数据集收费，需在LDC联盟官网注册会员再购买 [LDC账号注册地址](https://catalog.ldc.upenn.edu/signup)      [TACRED 下载地址](https://catalog.ldc.upenn.edu/LDC2018T24)

- **SemEval2010_task8** 

  ![image-20201005102419115](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20201005102419115.png)

  **数据集简介**:对于给定了的句子和两个做了标注的名词，从给定的关系清单中选出最合适的关系。数据集一共9种关系类别数，此外包含一类Other关系，含有6674实例数量。

  **获取方式**: [原始数据](http://semeval2.fbk.eu/semeval2.php?location=data)

- **FewRel**

  数据集简介:FewRel是目前最大规模的精标注关系抽取数据集，由孙茂松教授领导的清华大学自然语言处理实验室发布。一共100种关系类别数，含有70000实例数量。

  获取方式：[FewRel 网站地址](https://thunlp.github.io/fewrel.html)   [论文地址](http://aclweb.org/anthology/D18-1514)

- **NYT10** 

  **NYT-10**数据集文本来源于纽约时报，命名实体是通过 Stanford NER 工具并结合 Freebase 知识库进行标注的。实体对之间的关系是链接Freebase知识库中的关系，结合远监督方法所得到。该数据集共含有53种关系类型，包括特殊关系类型NA，即头尾实体无关系。

  **获取方式**:[原始数据](https://link.zhihu.com/?target=https%3A//cloud.tsinghua.edu.cn/f/11391e48b72749d8b60a/%3Fdl%3D1)

获取更多关系抽取数据集，可访问此处[Annotated-Semantic-Relationships-Datasets](https://github.com/davidsbatista/Annotated-Semantic-Relationships-Datasets)

### 1.3. 评测标准

**二分类**：

Accuracy = (预测正确的样本数)/(总样本数)=(TP+TN)/(TP+TN+FP+FN)

Precision = (预测为正例且正确预测的样本数)/(所有预测为正例的样本数) = TP/(TP+FP)

Recall = (预测为正例且正确预测的样本数)/(所有真实情况为正例的样本数) = TP/(TP+FN)

F1 = 2 * (Precision * Recall) / (Precision + Recall )

**多分类**：

Macro Average 

多类别（N类） F1/P/R的计算，即计算N个类别的F1/P/R，每次计算以当前类别为正例，其他所有类别为负例，最终将各类别结果求和并除以类别数取平均。

Micro Average

统计当前类别的TP、TN、FP、FN数量，再将该四类样本数各自求和作为新的TP、TN、FP、FN，计算F1/P/R公式同二分类。

**P@N（最高置信度预测精度）**:

通常在远监督关系抽取中使用到，由于知识库所含关系实例的不完善，会出现高置信度包含关系实例的实体对被叛为负例，从而低估了系统正确率。此时可以采用人工评价，将预测结果中知识库已包含的三元组移除，然后人工判断抽取关系实例是否正确，按照top N的准确率对抽取效果进行评价。

### 1.4. SOTA



Relation Extraction on **TACRED**：

| 模型            | average F1 | 论文题目                                                     | 年份 | 论文链接                               | code                                                   |
| --------------- | ---------- | ------------------------------------------------------------ | ---- | -------------------------------------- | ------------------------------------------------------ |
| BERTEM+MTB      | 71.5       | Matching the Blanks: Distributional Similarity for Relation Learning | 2019 | https://arxiv.org/pdf/1906.03158v1.pdf | https://github.com/plkmo/BERT-Relation-Extraction      |
| KnowBert-W+W    | 71.5       | Knowledge Enhanced Contextual Word Representations           | 2019 | https://arxiv.org/pdf/1909.04164v2.pdf |                                                        |
| DG-SpanBERT     | 71.5       | Efficient long-distance relation extraction with DG-SpanBERT | 2020 | https://arxiv.org/pdf/2004.03636v1.pdf |                                                        |
| SpanBERT        | 70.8       | SpanBERT: Improving Pre-training by Representing and Predicting Spans | 2019 | https://arxiv.org/pdf/1907.10529v3.pdf | https://github.com/facebookresearch/SpanBERT           |
| R-BERT          | 69.4       | Enriching Pre-trained Language Model with Entity Information for Relation Classification | 2020 | https://arxiv.org/pdf/1905.08284v1.pdf | https://github.com/wang-h/bert-relation-classification |
| C-GCN + PA-LSTM | 68.2       | Graph Convolution over Pruned Dependency Trees Improves Relation Extraction | 2018 | https://arxiv.org/pdf/1809.10185v1.pdf | https://github.com/qipeng/gcn-over-pruned-trees        |



Relation Extraction on **SemEval-2010 Task 8**：

| 模型                | average F1 | 论文题目                                                     | 年份 | 论文链接                                              | code                                                   |
| ------------------- | ---------- | ------------------------------------------------------------ | ---- | ----------------------------------------------------- | ------------------------------------------------------ |
| Skeleton-Aware BERT | 90.36      | Enhancing Relation Extraction Using Syntactic Indicators and Sentential Contexts | 2019 | https://arxiv.org/pdf/1912.01858v1.pdf                | https://github.com/wang-h/bert-relation-classification |
| EPGNN               | 90.2       | Improving Relation Classification by Entity Pair Graph       | 2019 | http://proceedings.mlr.press/v101/zhao19a/zhao19a.pdf |                                                        |
| BERTEM+MTB          | 89.5       | Matching the Blanks: Distributional Similarity for Relation Learning | 2019 | https://arxiv.org/pdf/1906.03158v1.pdf                | https://github.com/plkmo/BERT-Relation-Extraction      |
| R-BERT              | 89.25      | Enriching Pre-trained Language Model with Entity Information for Relation Classification | 2020 | https://arxiv.org/pdf/1905.08284v1.pdf                | https://github.com/wang-h/bert-relation-classification |
| KnowBert-W+W        | 89.1       | Knowledge Enhanced Contextual Word Representations           | 2019 | https://arxiv.org/pdf/1909.04164v2.pdf                |                                                        |
| Entity-Aware BERT   | 89         | Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers | 2019 | https://arxiv.org/pdf/1902.01030v2.pdf                | https://github.com/helloeve/mre-in-one-pass            |



Relation Extraction on **ACE 2005**：

| 模型          | RELATION F1 | ENTITY F1 | SENTENCE ENCODER | 论文题目                                                     | 年份 | 论文链接                                        | code                                 |
| ------------- | ----------- | --------- | ---------------- | ------------------------------------------------------------ | ---- | ----------------------------------------------- | ------------------------------------ |
| MRC4ERE++     | 62.1        | 85.5      | BERT base        | Asking Effective and Diverse Questions: A Machine Reading Comprehension based Framework for Joint Entity-Relation Extraction | 2020 | https://www.ijcai.org/Proceedings/2020/0546.pdf | https://github.com/TanyaZhao/MRC4ERE |
| Multi-turn QA | 60.2        | 84.8      | BERT base        | Entity-Relation Extraction as Multi-Turn Question Answering  | 2019 | https://arxiv.org/pdf/1905.05529v4.pdf          |                                      |
| MRT           | 59.6        | 83.6      | biLSTM           | Extracting Entities and Relations with Joint Minimum Risk Training | 2018 | https://www.aclweb.org/anthology/D18-1249       |                                      |
| GCN           | 59.1        | 84.2      | biLSTM           | Joint Type Inference on Entities and Relations via Graph Convolutional Networks | 2019 | https://www.aclweb.org/anthology/P19-1131       |                                      |
| Global        | 57.5        | 83.6      | biLSTM           | End-to-End Neural Relation Extraction with Global Optimization | 2017 | https://www.aclweb.org/anthology/D17-1182       |                                      |
| SPTree        | 55.6        | 83.4      | biLSTM           | End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures | 2016 | https://arxiv.org/pdf/1601.00770v3.pdf          | https://github.com/tticoin/LSTM-ER   |



Relation Extraction on **ACE 2004**：

| 模型            | RELATION F1 | ENTITY F1 | 论文题目                                                     | 年份 | 论文链接                                  | code                                                         |
| --------------- | ----------- | --------- | ------------------------------------------------------------ | ---- | ----------------------------------------- | ------------------------------------------------------------ |
| DYGIE           | 59.7        | 87.4      | A General Framework for Information Extraction using Dynamic Span Graphs | 2019 | https://arxiv.org/pdf/1904.03296v1.pdf    | https://github.com/luanyi/DyGIE                              |
| Multi-turn QA   | 49.4        | 83.6      | Entity-Relation Extraction as Multi-Turn Question Answering  | 2019 | https://arxiv.org/pdf/1905.05529v4.pdf    |                                                              |
| SPTree          | 48.4        | 81.8      | End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures | 2016 | https://arxiv.org/pdf/1601.00770v3.pdf    | https://github.com/tticoin/LSTM-ER                           |
| multi-head + AT | 47.45       | 81.64     | Adversarial training for multi-context joint entity and relation extraction | 2018 | https://arxiv.org/pdf/1808.06876v3.pdf    | https://github.com/bekou/multihead_joint_entity_relation_extraction |
| multi-head      | 47.14       | 81.16     | Joint entity recognition and relation extraction as a multi-head selection problem | 2018 | https://arxiv.org/pdf/1804.07847v3.pdf    | https://github.com/bekou/multihead_joint_entity_relation_extraction |
| Attention       | 45.7        | 79.6      | Going out on a limb: Joint Extraction of Entity Mentions and Relations without Dependency Trees | 2017 | https://www.aclweb.org/anthology/P17-1085 |                                                              |



Relation Extraction on **NYT**：

| 模型               | average F1 | 论文题目                                                     | 年份 | 论文链接                               | code                                          |
| ------------------ | ---------- | ------------------------------------------------------------ | ---- | -------------------------------------- | --------------------------------------------- |
| REDN               | 89.8       | Downstream Model Design of Pre-trained Language Model for Relation Extraction Task | 2020 | https://arxiv.org/pdf/2004.03786v1.pdf | https://github.com/slczgwh/REDN               |
| CASREL             | 89.6       | A Novel Cascade Binary Tagging Framework                     | 2019 | https://arxiv.org/pdf/1909.03227v4.pdf | https://github.com/weizhepei/CasRel           |
| HBT                | 89.5       | A Novel Cascade Binary Tagging Framework for Relational Triple Extraction | 2019 | https://arxiv.org/pdf/1909.03227v4.pdf | https://github.com/weizhepei/CasRel           |
| WDec               | 84.4       | Effective Modeling of Encoder-Decoder Architecture for Joint Entity and Relation Extraction | 2019 | https://arxiv.org/pdf/1911.09886v1.pdf | https://github.com/nusnlp/PtrNetDecoding4JERE |
| ETL-Span           | 78.0       | Joint Extraction of Entities and Relations Based on a Novel Decomposition Strategy | 2019 | https://arxiv.org/pdf/1909.04273v3.pdf | https://github.com/yubowen-ph/JointER         |
| CopyRE' OneDecoder | 72.2       | CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations with Multi-Task Learning | 2019 | https://arxiv.org/pdf/1911.10438v1.pdf | https://github.com/WindChimeRan/CopyMTL       |



Relation Extraction on **CoNLL04**：

| 模型                    | RELATION F1 | ENTITY F1 | 论文题目                                                     | 年份 | 论文链接                                  | code                                                         |
| ----------------------- | ----------- | --------- | ------------------------------------------------------------ | ---- | ----------------------------------------- | ------------------------------------------------------------ |
| SpERT                   | 71.47       | 88.94     | Span-based Joint Entity and Relation Extraction with Transformer Pre-training | 2019 | https://arxiv.org/pdf/1909.07755v3.pdf    | https://github.com/markus-eberts/spert                       |
| Multi-turn QA           | 68.9        | 87.8      | Entity-Relation Extraction as Multi-Turn Question Answering  | 2019 | https://arxiv.org/pdf/1905.05529v4.pdf    |                                                              |
| Global                  | 67.8        | 85.6      | End-to-End Neural Relation Extraction with Global Optimization | 2017 | https://www.aclweb.org/anthology/D17-1182 |                                                              |
| Biaffine attention      | 64.40       | 86.20     | End-to-end neural relation extraction using deep biaffine attention | 2018 | https://arxiv.org/pdf/1812.11275v1.pdf    | https://github.com/datquocnguyen/jointRE                     |
| Relation-Metric with AT | 62.29       | 84.15     | Neural Metric Learning for Fast End-to-End Relation Extraction | 2019 | https://arxiv.org/pdf/1905.07458v4.pdf    |                                                              |
| multi-head              | 62.04       | 83.9      | Joint entity recognition and relation extraction as a multi-head selection problem | 2018 | https://arxiv.org/pdf/1804.07847v3.pdf    | https://github.com/bekou/multihead_joint_entity_relation_extraction |



Relation Extraction on **FewRel**：

| 模型  | average F1 | 论文题目                                                     | 年份 | 论文链接                               | code                            |
| ----- | ---------- | ------------------------------------------------------------ | ---- | -------------------------------------- | ------------------------------- |
| ERNIE | 88.32      | ERNIE: Enhanced Language Representation with Informative Entities | 2019 | https://arxiv.org/pdf/1905.07129v3.pdf | https://github.com/thunlp/ERNIE |





## 2. 方法总结

### 2.1. 基于模式挖掘的方法

#### 2.1.1. 基于模板匹配的方法

**模板匹配**：在关系分类中应用广泛。对于给定实体对的一段文本，基于现有模板库进行上下文匹配。若结果满足模板对应关系类别，则将该关系类别作为实体对之间的关系。

常见的模板匹配方法主要包括：

- **人工模板**：常见于判断实体间存在的上下位关系。基本出发点是统计和总结关系模式，通过专家定义寻找关系在上下文中表达的字符，语法及语义特征，将此作为模式与文本进行匹配，进行关系实例的获取。
- **统计生成**：无须人工构建，主要基于搜索引擎进行统计模板抽取。具体地，将已知实体对作为查询语句，抓取搜索引擎返回的前n个结果文档并保留包含该实体对的句子集合，寻找包含实体对的最长字串作为统计模板，保留置信度较高的模板用于关系分类。

 ([Marti A. Hearst 1992](https://www.aclweb.org/anthology/C92-2082.pdf)) [<sup>[1]</sup>](#refer-anchor-1 )在该文中提出一种从不受限制的文本中自动获得下位词法关系的方法，用于提取分类关系is-a的实例：

![image-20201009171753511](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/Hearst1992.png)

#### 示例：

句子中上下位关系，比如hyponym(China; Asia countries)。从下面两个句子中都可以抽取出这种关系：

- Asia countries, especially China, Japan, and India...
- Asia countries, such as China, Japan, and India...

两个实体之间的especially和such as可以看做这种关系的特征。通过寻找更多表达这种关系的句子，构造规则模板，即可用于抽取构成上下位关系的实体，从而发现新的三元组。

#### 总结：

优点：

- 该方法准确率较高。
- 从某种意义上说，这是一种假设的工作，Hearst文中没有给出实验结果，但它对追随者影响很大，是之后Bootstraping方法的开篇之作。

缺点：

- 召回率较低，且关系类别有限，仅仅包含is-a的关系。
- 适用性有限，难以移植





#### 2.1.2. 基于依存句法

基于NLP工具（常见的有Stanford CoreNLP、spaCy、LTP、HanLP等）获取句子相关特征，对处理结果一般进行如下处理：

1. 输入文本完成分词、词性标注、命名实体识别、依存分析等处理步骤。
2. 基于语法规则抽取出相关语法信息，如 “主谓宾”、“定状补”等，从而得到句子中各成分之间的联系和关系。
3. 利用各成分之间相互关联关系总结出诸如定中关系，定语后置关系等抽取规则。
4. 设定规则模板，并根据规则对抽取结果进行严格测试与调优。

#### 示例

下面介绍一组基于LTP（语言技术平台）工具进行规则抽取三元组的例子：

- 输入文本：杨燕萍，女，中国共产党党员，系江西省第十一届政协主席许爱民的妻子。

- 经LTP得出依存句法分析结果：

  ![image-20201009163758374](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/%E4%BE%9D%E5%AD%98%E5%88%86%E6%9E%90%E7%A4%BA%E4%BE%8B.png)

  ​                                                                                                  依存句法分析结果示例

  

  ![image-20201009164128481](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/%E5%8F%A5%E6%B3%95%E5%85%B3%E7%B3%BB%E7%B1%BB%E5%9E%8B.png)

  ​                                                                                                          依存句法关系类型说明

  由图示可知，可以以谓语动词为出发点构建规则，对节点上词性以及边上的关系进行设定。当前句子核心谓词是“系”，从前向后遍历句子解析结果可以从“主席”开始分析，由于“主席”与左右两侧词汇均构成定中关系且两侧词汇均被识别为命名实体。由此，可以提取出一项（政协，主席，许爱民）定中关系三元组。

####  总结

手写规则的 **优点** ：

- 人工设定规则，准确率高(high-precision)
- 结合专家知识，进行特定领域定制
- 构建简单，适合小规模关系类别数据

**缺点**：

- 规则总结无法穷尽，导致低召回率(low-recall)
- 所有关系类别须定义相关规则pattern，耗时耗力
- 难以维护及跨领域移植



### 2.2. 监督学习

#### 2.2.1. 机器学习

#### 2.2.1.1. 基于特征向量的方法

基于特征向量的方法是一种简单且行之有效 的关系抽取运用。其主要思想为：给定关系句子实例，从上下文中提取出具有类间区分度的特征（如词法信息，语法信息等），构造形成多维度加权特征向量，选取合适的分类器进行关系抽取模型训练。

基于特征向量的方法需要解决的三个基本问题：特征项选取，特征权重计算和分类器选择。

- 特征项。作为向量模型的骨架，它需要包含足够的语义信息来表征自然文本，又需要在语义关系间具有良好的区分度。常见的特征项有：词法、实体、句法、语义及上下文结构化信息等。

- 特征权重计算。众多候选特征项，对最终关系分类的贡献度不可能完全一样，比如实体间语义关系往往比实体词汇、句子长度等特征更加重要。因此，需要进行特征重要性权重计算。这里提供两种权重方法计算思路：一、公式计算权值并排序，如布尔权重、特征频度<sup>[5]</sup>。二、基于优化算法进行最优权向量搜索<sup>[6]</sup>

- 分类器选取。特征向量构造完毕后，下一步便是选取合适的分类器。下面介绍两种具有代表性的分类器：

  - **最大熵模型**（**Maximum Entropy Model**）

    [Kambhatla 2004](https://www.aclweb.org/anthology/P04-3022/)<sup>[2]</sup>基于文本中实体词，实体类型，实体引用类型、语法以及句法树在内的多种特征，采用最大熵分类器，对不同特征叠加后进行了实验对比，并在ACE RDC2003语料的子类关系中获得了52.8的F1值，表明多层面语言学特征能有效提升关系分类模型的效果。

    ![image-20201010130214309](https://github.com/BDBC-KG-NLP/IE-Survey/blob/master/image/Kambhatla2004.png)

  - **支持向量机(SVM)**

    [Zhou et al.,2005](https://www.aclweb.org/anthology/P05-1053/)<sup>[3]</sup>在Kambhatla前期基础上，融入基本的词组块信息特征组合，基于SVM获得了55.5的F1性能，并得出实体类别特征对于关系抽取结果提升最大的结论。[Zhao et al.，2005](https://www.aclweb.org/anthology/P05-1052/)<sup>[4]</sup>引用了文字特征，语句解析和深层语法依存特征等组合。[Jiang et al.,2007](https://www.aclweb.org/anthology/N07-1015/)<sup>[5]</sup>选取文本词序列、句法、依存关系等特征组合，以不同类别特征对抽取结果贡献度进行了评估，他们总结出在这些类别特征中选取最基本的单位特征便可以有效的提升关系抽取的性能，而过于复杂的特征带来的性能提升效果则一般。



**小结：**

基于特征向量的方法是关系抽取中最常见的方法，特征工程是该方法核心。研究者启发式地以多层次语言特征为切入点，并构造特征向量，结合分类器训练，可以取得不错的效果。但该方法现如今难以寻找有效新特征，性能提升较为有限。

#### 2.2.1.2. 基于核函数的方法

针对特征提取具有的局限性，便有研究者另辟蹊径，使用核函数的方法进行关系抽取。基于核函数的方法无需人为构造显性特征，而是以输入文本实例的字符串或者是句法分析树结构作为输入，通过计算任意两个输入对象间的核相似度函数来训练分类模型。基于核函数的方法通过核函数映射综合了更多方面的知识信息，使实体间关系表示更加灵活。核函数类型众多，有包含诸如多项式核函数，向量空间核函数，P-光谱核函数，全序列核函数等。基于核函数的方法灵活性较高，对于多个不同个体核函数可以进行复合，从而得到针对具体任务的核函数。

**方法原理**：在初始特征空间下，核函数将该空间里的数据点映射到一个新的特征空间下，在该空间中训练线性分类器。其本质是将句子潜在的隐式特征向量投影到新的特征空间，并通过计算投影的内积来表示输入空间特征向量的相似性，最终达到判定实体间关系类别相似性的效果。

基于核函数的方法抽取关系一般步骤：

1. 针对句子中隐含的特征信息，选用合适的解析结构，如语法树等进行语句剖析；
2. 在此基础上选择合适的基础核函数，计算解析结构中成分之间的相似性；
3. 在基础核函数之上，将多个核函数复合，以充分利用各种隐式特征，提高分类精度。



- 浅层树核（[Zelenko，2003](https://jmlr.org/papers/v3/zelenko03a.html)）<sup>[6]</sup>

- 依存树核（[Culotta et al., 2004](https://www.aclweb.org/anthology/P04-1054/)）<sup>[7]</sup>

- 最短依存树核（[Bunescu et al., 2005](https://www.aclweb.org/anthology/H05-1091/)）<sup>[8]</sup>

- 卷积树核（[Zhang et al., 2006](https://www.aclweb.org/anthology/P06-1104/)<sup>[9]</sup>；[Zhou et al., 2007](https://www.aclweb.org/anthology/D07-1076/)<sup>[10]</sup>）

- 其他的还有诸如

  - constituent parse trees [Collins & Duffy, 2001] 
  - string sequencies [Cancedda & al., 2003]
  - directed acyclic graphs [Suzuki & al., 2003]

  - dependency parse trees [Moschitti, 2006]
  - feature-enriched/semantic tree kernel [Plank & Moschitti,2013; Sun & Han, 2014]

**小结**:

基于核函数的方法可以规避构造基于向量方法中显式特征集合，且更能够充分利用句子的长距离特征。然而核方法将多个不同核函数符合后，虽然可以表达高纬度或无穷维度特征空间，但也导致该方法学习和训练速度 过程较为缓慢，对于大规模数据抽取场景耗费时空代价巨大。

二者比较

| 方法               | 特征项                                       | 特征表示方法 | 核心步骤       |
| ------------------ | -------------------------------------------- | ------------ | -------------- |
| 基于特征向量的方法 | 词、词性、上下文结构信息、依存分析、句法树等 | 显式         | 特征工程       |
| 基于核函数的方法   | 依存树核、卷积树核等                         | 隐式高维     | 设计核函数计算 |



## 4. Paper List

### 4.1. 论文列表

#### 4.1.1. 监督类方法

##### 4.1.1.1. 利用语法信息的方法

|                           论文题目                           | 抽取任务 |                            关键词                            |                           论文链接                           | 会议及年份 | code                                                         |
| :----------------------------------------------------------: | :------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :--------: | ------------------------------------------------------------ |
| Attention Guided Graph Convolutional Networks for Relation Extraction | 关系提取 | 注意力导向图卷积网络（AGGCN）；语义依赖树；软修剪；自动学习子结构； | [https://www.aclweb.org/anthology/P19-1024.pdf](https://www.aclweb.org/anthology/P19-1024.pdf) |  ACL2019   |                                                              |
| A Richer-but-Smarter Shortest Dependency Path with Attentive Augmentation for Relation Extraction | 关系提取 |   最短依赖路径SDP；注意力模型；深度神经模型；LSTM网络；CNN   | [https://www.aclweb.org/anthology/N19-1298](https://www.aclweb.org/anthology/N19-1298) | NAACL 2019 | [https://github.com/catcd/RbSP](https://github.com/catcd/RbSP) |

##### 4.1.1.2. 不利用语法信息的方法 

|                           论文题目                           |       抽取任务        |                      关键词                       |                           论文链接                           | 会议及年份 | code |
| :----------------------------------------------------------: | :-------------------: | :-----------------------------------------------: | :----------------------------------------------------------: | :--------: | ---- |
| Joint Type Inference on Entities and Relations via Graph Convolutional Networks | 抽取三元组的joint任务 | 实体关系联合推断；图卷积模型（GCN）；二元关系分类 | [https://pdfs.semanticscholar.org/7ce8/ce2768907421fb1a6cbfe13a8a36992721a7.pdf](https://pdfs.semanticscholar.org/7ce8/ce2768907421fb1a6cbfe13a8a36992721a7.pdf) |  ACL2019   |      |
| GraphRel: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction | 抽取三元组的joint任务 |           端到端关系抽取；图卷积网络；            | [https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf](https://tsujuifu.github.io/pubs/acl19_graph-rel.pdf) |  ACL2019   |      |
| Exploiting Entity BIO Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data |       关系抽取        |     BIO字符/词嵌入；多任务体系结构；关系分类      | [https://arxiv.org/pdf/1906.08931.pdf](https://arxiv.org/pdf/1906.08931.pdf) |  ACL2019   |      |
| Entity-Relation Extraction as Multi-turn Question Answering  |       关系抽取        |         多回合QA；上下文识别答案范围任务          | [https://arxiv.org/pdf/1905.05529.pdf](https://arxiv.org/pdf/1905.05529.pdf) |  ACL2019   |      |
| Graph Neural Networks with Generated Parameters for Relation |       关系抽取        |          图神经网络（GNN）；多跳关系推理          | [https://arxiv.org/pdf/1902.00756.pdf](https://arxiv.org/pdf/1902.00756.pdf) |  ACL2019   |      |
| Kernelized Hashcode Representations for Biomedical Relation Extraction |       关系分类        |     核化的局部敏感哈希（KLSH）；降低计算成本      | [https://arxiv.org/pdf/1711.04044.pdf](https://arxiv.org/pdf/1711.04044.pdf) |  ACL2019   |      |
| Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs |       关系抽取        |          图神经网络模型；文档级关系提取           | [https://arxiv.org/pdf/1909.00228v1.pdf](https://arxiv.org/pdf/1909.00228v1.pdf) | EMNLP2019  |      |

#### 4.1.2. 远监督方法

|                           论文题目                           | 抽取任务 |                            关键词                            |                           论文链接                           | 会议及年份 |                             code                             |
| :----------------------------------------------------------: | :------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :--------: | :----------------------------------------------------------: |
| Hybrid Attention-based Prototypical Networks for Noisy Few-Shot Relation Classification | 关系分类 |               远监督；噪声；混合注意力圆形网络               | [https://gaotianyu1350.github.io/assets/aaai2019_hatt_paper.pdf](https://gaotianyu1350.github.io/assets/aaai2019_hatt_paper.pdf) |  AAAI2019  |             https://github.com/thunlp/HATT-Proto             |
| A Hierarchical Framework for Relation Extraction with Reinforcement Learning | 关系提取 | 增强关系类型系和实体交互；分层强化学习（HRL）框架；远监督数据集 | [https://arxiv.org/pdf/1811.03925.pdf](https://arxiv.org/pdf/1811.03925.pdf) |  AAAI2019  |                                                              |
| Cross-relation Cross-bag Attention for Distantly-supervised Relation Extraction | 关系提取 | 远监督抗噪；Cross-relation Cross-bag Selective Attention；多实例学习；句子级别；注意力机制；关注高质量实体对 | [https://arxiv.org/pdf/1812.10604.pdf](https://arxiv.org/pdf/1812.10604.pdf) |  AAAI2019  |                                                              |
| Structured Minimally Supervised Learning for Neural Relation Extraction | 关系提取 |             最小监督；学习的表示形式；结构化学习             | [https://arxiv.org/pdf/1904.00118.pdf](https://arxiv.org/pdf/1904.00118.pdf) | NAACL2019  |                                                              |
| Combining Distant and Direct Supervision for Neural Relation Extraction | 关系提取 |                  降噪；监督学习+远监督模型                   |             https://arxiv.org/pdf/1810.12956.pdf             | NAACL2019  | [https://github.com/allenai/comb_dist_direct_relex/](https://github.com/allenai/comb_dist_direct_relex/) |
| Distant Supervision Relation Extraction with Intra-Bag and Inter-Bag Attentions | 关系提取 |                    句子级别的Attention；                     | [https://www.aclweb.org/anthology/N19-1288.pdf](https://www.aclweb.org/anthology/N19-1288.pdf) | NAACL2019  |                                                              |
| GAN Driven Semi-distant Supervision for Relation Extraction  | 关系提取 |                半远监督；生成对抗网络（GAN）                 | [https://www.aclweb.org/anthology/N19-1307](https://www.aclweb.org/anthology/N19-1307) | NAACL 2019 |                                                              |
| Improving Distantly-Supervised Relation Extraction with Joint Label Embedding | 关系提取 |                 多层注意力模型；联合标签嵌入                 | [https://www.aclweb.org/anthology/D19-1395.pdf](https://www.aclweb.org/anthology/D19-1395.pdf) | NAACL 2019 |                                                              |
| Self-Attention Enhanced CNNs and Collaborative Curriculum Learning for Distantly Supervised Relation Extraction | 关系提取 |     协作式学习；卷积神经网（CNN)；卷积运算内部自注意机制     | [https://www.aclweb.org/anthology/D19-1037.pdf](https://www.aclweb.org/anthology/D19-1037.pdf) | NAACL 2019 |                                                              |



## 5. 相关文献

- [1] Automatic Acquisition of Hyponyms From Large Text Corpora.
- [2] Combining Lexical, Syntactic, and Semantic Features with Maximum Entropy Models for Information Extraction.
- [3] Extracting Relations with Integrated Information Using Kernel Methods
- [4] Exploring Various Knowledge in Relation Extraction
- [5] A Systematic Exploration of the Feature Space for Relation Extraction
- [6] Kernel Methods for Relation Extraction
- [7] Dependency Tree Kernels for Relation Extraction 
- [8] A Shortest Path Dependency Kernel for Relation Extraction
- [9] A Composite Kernel to Extract Relations between Entities with Both Flat and Structured Features  
- [10] Tree Kernel-Based Relation Extraction with Context-Sensitive Structured Parse Tree Information



## 6. 参考资源



